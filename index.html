<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Deformable Neural Radiance Fields creates free-viewpoint portraits (nerfies) from casually captured videos.">
  <meta name="keywords" content="Nerfies, D-NeRF, NeRF">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Imagine-2-Drive: High-Fidelity World Modeling in CARLA for Autonomous Vehicles</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Imagine-2-Drive: High-Fidelity World Modeling in CARLA for Autonomous Vehicles</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://keunhong.com"><mark>Anant Garg</mark></a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://utkarshsinha.com">K. Madhav Krishna</a><sup>1</sup>,</span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>International Institute of Information Technology - Hyderabad</span>
          </div>
          <div class="is-size-5 publication-authors">
            <!-- <span class="author-block"><sup>1</sup>International Institute of Information Technology - Hyderabad</span> -->
            <p><mark>Author is looking for MS/PhD positions for FY 2025</mark></p>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://drive.google.com/file/d/1dYEh2VItCpv45ILI-hOjXenw9oU8unjI/view?usp=drive_link"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span> -->
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://youtu.be/56etmpWrnFg "
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/anantagrg/Imagine-2-Drive"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (coming soon)</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<section class="hero teaser" style="margin-bottom: -5rem;">

  <div class="columns is-centered has-text-centered">
    <div class="column is-three-fifths">
      <h2 class="title is-3">VISTA Future Frames Denoising Results</h2>
      
      <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
        <source src="./static/videos/vista_denoise.mp4"
                type="video/mp4">
      </video>
      <p class="has-text-left">
        Denoising of future frames predictions using VISTA. Frames are predicted according to the input trajectory
        shown as color coded. Unlike single-step models, VISTA predicts future states simultaneously, eliminating compounding errors.
      </p>
    </div>
  </div>

  <hr>

  <div class="container is-max-desktop">
    <div class="hero-body">
      <div class="content">
        <img id="teaser-image" src="./static/images/teaser.jpg" alt="Teaser Image" height="100%">
      </div>
      <p>
        Using front camera RGB image as the sole input modality, Imagine-2-Drive provides a framework to combine VISTAPlan, VISTA
        based World Model with DPA, a multi-modal diffusion based policy actor. Given a trajectory output by DPA, shown in Red and the
        corresponding predicted future observations from VISTAPlan, the DDPO tries to find an optimal policy by maximizing the cumulative
        sum of rewards from future states. The proposed architecture is shown along with the gradient flow for joint end-to-end training.
      </p>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            In autonomous driving with image based state
            space, accurate prediction of future events and modeling diverse
            behavioral modes are essential for safety and effective decision-
            making. World model-based Reinforcement Learning (WMRL)
            approaches offers a promising solution by simulating future
            states from current state and actions. However, utility of world
            models is often limited by typical RL policies being limited
            to deterministic or single gaussian distribution. By failing to
            capture the full spectrum of possible actions, reduces their
            adaptability in complex, dynamic environments. In this work,
            we introduce Imagine-2-Drive, a framework that consists of
            two components, VISTAPlan, a high-fidelity world model for
            accurate future prediction and Diffusion Policy Actor (DPA),
            a diffusion based policy to model multi-modal behaviors for
            trajectory prediction. We use VISTAPlan to simulate and eval-
            uate trajectories from DPA and use Denoising Diffusion Policy
            Optimization (DDPO) to train DPA to maximize the cumulative
            sum of rewards over the trajectories. We analyze the benefits
            of each component and the framework as a whole in CARLA
            with standard driving metrics. As a consequence of our twin
            novelties- VISTAPlan and DPA, we significantly outperform
            the state of the art (SOTA) world models on standard driving
            metrics by 15% and 20% on Route Completion and Success
            Rate respectively.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/56etmpWrnFg"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    <!--/ Paper video. -->
  </div>
</section>

<section class="section">

  <div class="columns is-centered has-text-centered">
    <div class="column is-two-fifths">
      <h2 class="title is-3">VISTA Future Frames Prediction Results</h2>
      <p class="has-text-left">
        Future obervation predictions from the VISTAPlan World Model, conditioned on the
        input trajectory and current observations. Demonstrates the 
        VISTAPlan’s ability to accurately predict future observations based on
        the provided context, highlighting its robust trajectory prediction capabilities.
      </p>
      <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
        <source src="./static/videos/vista_prediction.mp4"
                type="video/mp4">
      </video>
    </div>
  </div>

  <!-- <div class="columns is-centered has-text-centered">
    <div class="column is-three-fifths">
      <h2 class="title is-3">VISTA Future Frames Denoising Results</h2>
      <p class="has-text-left">
        Future obervation predictions from the VISTAPlan World Model, conditioned on the
        input trajectory and current observations. Demonstrates the 
        VISTAPlan’s ability to accurately predict future observations based on
        the provided context, highlighting its robust trajectory prediction capabilities.
      </p>
      <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
        <source src="./static/videos/vista_denoise.mp4"
                type="video/mp4">
      </video>
    </div>
  </div> -->

  <div class="container is-max-desktop">

    <div class="columns is-centered">

      <!-- Visual Effects. -->
      <div class="column">
        <div class="content">
          <h2 class="title is-3">Long Run Demo</h2>
          <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/i2d_demo2.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
      <!--/ Visual Effects. -->

      <!-- Matting. -->
      <div class="column">
        <div class="columns is-centered">
          <div class="column content">
            <h2 class="title is-3">Multi-Modal Demo</h2>
            <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/i2d_demo_multi_modal_1.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div>
    </div>
    <div class="columns is-centered">
  </section>



<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
